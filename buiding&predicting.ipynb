{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f21290fe-26ad-4acc-ba64-9f607e108b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "   Transaction_ID   User_ID  Transaction_Amount Transaction_Date  \\\n",
      "0            1001  68389745            69635000    1/1/2024 0:00   \n",
      "1            1002  42122340            53486000    1/1/2024 0:01   \n",
      "2            1003  87539955            24262000    1/1/2024 0:02   \n",
      "3            1004  98657863            56019000    1/1/2024 0:03   \n",
      "4            1005  88084360            87823000    1/1/2024 0:04   \n",
      "\n",
      "  Transaction_Time Transaction_Location  Merchant_ID  Device_ID Card_Type  \\\n",
      "0          0:00:00         Surkhandarya         6710       2060    UzCard   \n",
      "1          0:01:00             Namangan         6498       2797    UzCard   \n",
      "2          0:02:00               Navoiy         5039       2519      Humo   \n",
      "3          0:03:00              Bukhara         6115       2641      Humo   \n",
      "4          0:04:00              Andijan         5072       2923      Humo   \n",
      "\n",
      "  Transaction_Currency Transaction_Status  Previous_Transaction_Count  \\\n",
      "0                  UZS         Successful                          35   \n",
      "1                  USD         Successful                          35   \n",
      "2                  UZS           Reversed                          25   \n",
      "3                  UZS             Failed                          44   \n",
      "4                  UZS             Failed                          21   \n",
      "\n",
      "   Distance_Between_Transactions_km  Time_Since_Last_Transaction_min  \\\n",
      "0                           3481.19                               30   \n",
      "1                           4341.04                             1073   \n",
      "2                           4780.35                              132   \n",
      "3                            719.43                               41   \n",
      "4                           4691.06                              458   \n",
      "\n",
      "  Authentication_Method  Transaction_Velocity Transaction_Category  isFraud  \n",
      "0                   2FA                     5             Transfer        1  \n",
      "1             Biometric                     9             Cash Out        1  \n",
      "2                   2FA                     7              Cash In        1  \n",
      "3             Biometric                     1              Payment        1  \n",
      "4              Password                     8             Cash Out        1  \n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = Path(r\"C:\\BFSI\\card_fraud.csv\")\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "690f84df-c7d1-441b-9caf-7b651a94af3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify target column\n",
    "if \"isFraud\" in df.columns:\n",
    "    target = \"isFraud\"\n",
    "else:\n",
    "    raise ValueError(\"Target column 'isFraud' not found. Please verify dataset.\")\n",
    "\n",
    "# Drop ID-like columns (do NOT use in training)\n",
    "id_columns = [\"Transaction_ID\", \"User_ID\", \"Merchant_ID\", \"Device_ID\"]\n",
    "existing_ids = [col for col in id_columns if col in df.columns]\n",
    "\n",
    "X = df.drop(columns=existing_ids + [target])\n",
    "y = df[target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e36bd250-abc6-401c-bc8f-8a803a0dd45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 80000\n",
      "Testing samples: 20000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training samples:\", len(X_train))\n",
    "print(\"Testing samples:\", len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f1e4fbc-c570-4b37-80ad-d0888853dac1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated triple-quoted string literal (detected at line 32) (2939586900.py, line 5)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mOne-Hot Encoding'''\u001b[39m\n                    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated triple-quoted string literal (detected at line 32)\n"
     ]
    }
   ],
   "source": [
    "''Build Preprocessing Pipeline\n",
    "Includes:\n",
    "Imputation\n",
    "Scaling\n",
    "One-Hot Encoding'''\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "categorical_features = X_train.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "numeric_transform = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transform = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transform, numeric_features),\n",
    "        (\"cat\", categorical_transform, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c05d1c-42da-4bfb-b4c1-037545b76af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_lr = Pipeline(steps=[\n",
    "    ('preprocess', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, class_weight='balanced'))\n",
    "])\n",
    "\n",
    "model_lr.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4576275-fe15-4e88-95ed-426095b587ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "def evaluate(model, name):\n",
    "    preds = model.predict(X_test)\n",
    "    probs = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    print(f\"\\n=== {name} Evaluation ===\")\n",
    "    print(classification_report(y_test, preds))\n",
    "    print(\"ROC AUC Score:\", roc_auc_score(y_test, probs))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, preds))\n",
    "\n",
    "evaluate(model_lr, \"Logistic Regression\")\n",
    "evaluate(model_rf, \"Random Forest\")\n",
    "\n",
    "try:\n",
    "    evaluate(model_lgb, \"LightGBM\")\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bed869b-3e10-4978-85cc-009c76f46841",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "\n",
    "for name, model in {\n",
    "    \"LR\": model_lr,\n",
    "    \"RF\": model_rf,\n",
    "    \"LGB\": model_lgb if 'model_lgb' in globals() else None\n",
    "}.items():\n",
    "    if model:\n",
    "        probs = model.predict_proba(X_test)[:, 1]\n",
    "        scores[name] = roc_auc_score(y_test, probs)\n",
    "\n",
    "best_model_name = max(scores, key=scores.get)\n",
    "print(\"Best Model:\", best_model_name)\n",
    "\n",
    "best_model = {\n",
    "    \"LR\": model_lr,\n",
    "    \"RF\": model_rf,\n",
    "    \"LGB\": model_lgb if 'model_lgb' in globals() else None\n",
    "}[best_model_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6f03ce3-904e-437e-979a-ada5098018f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjoblib\u001b[39;00m\n\u001b[32m      3\u001b[39m MODEL_PATH = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mBFSI\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mfraud_detection_model.pkl\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m joblib.dump(best_model, MODEL_PATH)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mModel saved to:\u001b[39m\u001b[33m\"\u001b[39m, MODEL_PATH)\n",
      "\u001b[31mNameError\u001b[39m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "MODEL_PATH = r\"C:\\BFSI\\fraud_detection_model.pkl\"\n",
    "joblib.dump(best_model, MODEL_PATH)\n",
    "\n",
    "print(\"Model saved to:\", MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6309845-f31c-48ad-b4f9-4738005b690f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f7f3af-2db0-4d42-b0a5-5f18580d4468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90146720-f551-468b-84f4-c3faaa743bf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
